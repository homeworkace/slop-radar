{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a890c483-8fcb-4b7b-a545-f7ef774edefd",
   "metadata": {},
   "source": [
    "# Installing requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239a68b-1f68-4550-a536-5343688fe180",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub\n",
    "!pip install datasets\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e3ba1c-efc1-461f-98e2-9f98aa943001",
   "metadata": {},
   "source": [
    "# Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05a9727e-86e4-4b5f-a2bf-3b2a29b8716e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81254f20bccf4e4ba566fbc737ea73e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()\n",
    "hugging_face_dataset = datasets.load_dataset('lmsys/chatbot_arena_conversations')\n",
    "dataset = hugging_face_dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "25810d5d-4f05-45f7-b69d-75b16ac4d49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>judge</th>\n",
       "      <th>conversation_a</th>\n",
       "      <th>conversation_b</th>\n",
       "      <th>turn</th>\n",
       "      <th>anony</th>\n",
       "      <th>language</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>openai_moderation</th>\n",
       "      <th>toxic_chat_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>8120899314f74641b09c2aa114d4d253</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>model_b</td>\n",
       "      <td>arena_user_316</td>\n",
       "      <td>[{'content': 'Salut ! Comment Ã§a va ce matin ?...</td>\n",
       "      <td>[{'content': 'Salut ! Comment Ã§a va ce matin ?...</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>French</td>\n",
       "      <td>1.682354e+09</td>\n",
       "      <td>{'categories': {'harassment': False, 'harassme...</td>\n",
       "      <td>{'roberta-large': {'flagged': False, 'probabil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         question_id     model_a     model_b   winner  \\\n",
       "33  8120899314f74641b09c2aa114d4d253  alpaca-13b  vicuna-13b  model_b   \n",
       "\n",
       "             judge                                     conversation_a  \\\n",
       "33  arena_user_316  [{'content': 'Salut ! Comment Ã§a va ce matin ?...   \n",
       "\n",
       "                                       conversation_b  turn  anony language  \\\n",
       "33  [{'content': 'Salut ! Comment Ã§a va ce matin ?...     6   True   French   \n",
       "\n",
       "          tstamp                                  openai_moderation  \\\n",
       "33  1.682354e+09  {'categories': {'harassment': False, 'harassme...   \n",
       "\n",
       "                                       toxic_chat_tag  \n",
       "33  {'roberta-large': {'flagged': False, 'probabil...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset['turn'] > 3][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cff15e-f869-42f2-8e2b-df557967b169",
   "metadata": {},
   "source": [
    "# Create text-author pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d29aeca5-eec7-476e-9480-826fe4589729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list for processed data\n",
    "text_author_pairs = []\n",
    "\n",
    "# Iterate through each row of the DataFrame\n",
    "for _, row in dataset.iterrows():\n",
    "    # Process conversation_a (assistant role)\n",
    "    for message in row[\"conversation_a\"]:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            text_author_pairs.append({\n",
    "                \"text\": message[\"content\"],\n",
    "                \"author\": row[\"model_a\"]\n",
    "            })\n",
    "\n",
    "    # Process conversation_b (assistant role)\n",
    "    for message in row[\"conversation_b\"]:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            text_author_pairs.append({\n",
    "                \"text\": message[\"content\"],\n",
    "                \"author\": row[\"model_b\"]\n",
    "            })\n",
    "\n",
    "    # Process user messages (common across both conversations)\n",
    "    for message in row[\"conversation_a\"]:  # Check only `conversation_a` since user messages are identical\n",
    "        if message[\"role\"] == \"user\":\n",
    "            text_author_pairs.append({\n",
    "                \"text\": message[\"content\"],\n",
    "                \"author\": \"human\"\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8779269b-827d-44a0-842a-7007c968ace0",
   "metadata": {},
   "source": [
    "# Create token count vectors for each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "68220c4b-c0da-4024-8ee0-cf878edcc662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             chatglm-6b  koala-13b  oasst-pythia-12b  alpaca-13b  vicuna-13b  \\\n",
      "00                  136         64               238          47         155   \n",
      "000                 114        204               129          37         227   \n",
      "0000                  2          0                 0           0           1   \n",
      "00000                 0          0                 0           0           0   \n",
      "000000                1          2                 0           0           1   \n",
      "...                 ...        ...               ...         ...         ...   \n",
      "ï½”ï½                    0          0                 0           0           0   \n",
      "ï½—ï½…ï½…ï½‹ï½“                 0          0                 0           0           0   \n",
      "ğ˜€ğ—¶ğ—ºğ—½ğ—¹ğ—²                0          0                 0           0           0   \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»            0          0                 0           0           0   \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»ğ˜€           0          0                 0           0           0   \n",
      "\n",
      "             dolly-v2-12b  stablelm-tuned-alpha-7b  llama-13b  fastchat-t5-3b  \\\n",
      "00                     18                       52         23              37   \n",
      "000                   100                       54         69              86   \n",
      "0000                    1                        0          0               1   \n",
      "00000                   0                        0          0               0   \n",
      "000000                  2                        1          0               0   \n",
      "...                   ...                      ...        ...             ...   \n",
      "ï½”ï½                      0                        0          0               0   \n",
      "ï½—ï½…ï½…ï½‹ï½“                   0                        0          0               0   \n",
      "ğ˜€ğ—¶ğ—ºğ—½ğ—¹ğ—²                  0                        0          0               0   \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»              0                        0          0               0   \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»ğ˜€             0                        0          0               0   \n",
      "\n",
      "             gpt-3.5-turbo  gpt-4  RWKV-4-Raven-14B  claude-v1  mpt-7b-chat  \\\n",
      "00                      39     78                27         57           32   \n",
      "000                    149    216                80        464           94   \n",
      "0000                     0      0                 0          0            0   \n",
      "00000                    0      0                 0          0            0   \n",
      "000000                   1      0                 0          0            0   \n",
      "...                    ...    ...               ...        ...          ...   \n",
      "ï½”ï½                       0      0                 0          0            0   \n",
      "ï½—ï½…ï½…ï½‹ï½“                    0      0                 0          0            0   \n",
      "ğ˜€ğ—¶ğ—ºğ—½ğ—¹ğ—²                   0      1                 0          0            0   \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»               0      1                 0          0            0   \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»ğ˜€              0      0                 0          0            0   \n",
      "\n",
      "             palm-2  claude-instant-v1  vicuna-7b  wizardlm-13b  \\\n",
      "00               87                 18         83             6   \n",
      "000             252                227         60            40   \n",
      "0000              1                  0          8             3   \n",
      "00000             0                  1          0             0   \n",
      "000000            2                  1          0             0   \n",
      "...             ...                ...        ...           ...   \n",
      "ï½”ï½                0                  0          0             0   \n",
      "ï½—ï½…ï½…ï½‹ï½“             0                  0          0             0   \n",
      "ğ˜€ğ—¶ğ—ºğ—½ğ—¹ğ—²            0                  0          0             0   \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»        0                  0          0             0   \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»ğ˜€       0                  0          0             0   \n",
      "\n",
      "             gpt4all-13b-snoozy  guanaco-33b  \n",
      "00                           28            3  \n",
      "000                          45           20  \n",
      "0000                         11            1  \n",
      "00000                         0            0  \n",
      "000000                        0            0  \n",
      "...                         ...          ...  \n",
      "ï½”ï½                            0            0  \n",
      "ï½—ï½…ï½…ï½‹ï½“                         0            0  \n",
      "ğ˜€ğ—¶ğ—ºğ—½ğ—¹ğ—²                        0            0  \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»                    0            0  \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»ğ˜€                   0            0  \n",
      "\n",
      "[195411 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract paragraphs and their authors\n",
    "paragraphs = [entry[\"text\"] for entry in text_author_pairs]\n",
    "authors = [entry[\"author\"] for entry in text_author_pairs]\n",
    "\n",
    "# Vectorize the paragraphs\n",
    "vectorizer = CountVectorizer()\n",
    "x_train = vectorizer.fit_transform(paragraphs)  # Each row is a paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaddb289-5636-47db-a7c2-fe29843d88c5",
   "metadata": {},
   "source": [
    "# Group texts by author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "afa5cb24-c9d2-4764-a776-2f24dda360d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             chatglm-6b  koala-13b  oasst-pythia-12b  alpaca-13b  vicuna-13b  \\\n",
      "00                  136         64               238          47         155   \n",
      "000                 114        204               129          37         227   \n",
      "0000                  2          0                 0           0           1   \n",
      "00000                 0          0                 0           0           0   \n",
      "000000                1          2                 0           0           1   \n",
      "...                 ...        ...               ...         ...         ...   \n",
      "ï½”ï½                    0          0                 0           0           0   \n",
      "ï½—ï½…ï½…ï½‹ï½“                 0          0                 0           0           0   \n",
      "ğ˜€ğ—¶ğ—ºğ—½ğ—¹ğ—²                0          0                 0           0           0   \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»            0          0                 0           0           0   \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»ğ˜€           0          0                 0           0           0   \n",
      "\n",
      "             dolly-v2-12b  stablelm-tuned-alpha-7b  llama-13b  fastchat-t5-3b  \\\n",
      "00                     18                       52         23              37   \n",
      "000                   100                       54         69              86   \n",
      "0000                    1                        0          0               1   \n",
      "00000                   0                        0          0               0   \n",
      "000000                  2                        1          0               0   \n",
      "...                   ...                      ...        ...             ...   \n",
      "ï½”ï½                      0                        0          0               0   \n",
      "ï½—ï½…ï½…ï½‹ï½“                   0                        0          0               0   \n",
      "ğ˜€ğ—¶ğ—ºğ—½ğ—¹ğ—²                  0                        0          0               0   \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»              0                        0          0               0   \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»ğ˜€             0                        0          0               0   \n",
      "\n",
      "             gpt-3.5-turbo  gpt-4  RWKV-4-Raven-14B  claude-v1  mpt-7b-chat  \\\n",
      "00                      39     78                27         57           32   \n",
      "000                    149    216                80        464           94   \n",
      "0000                     0      0                 0          0            0   \n",
      "00000                    0      0                 0          0            0   \n",
      "000000                   1      0                 0          0            0   \n",
      "...                    ...    ...               ...        ...          ...   \n",
      "ï½”ï½                       0      0                 0          0            0   \n",
      "ï½—ï½…ï½…ï½‹ï½“                    0      0                 0          0            0   \n",
      "ğ˜€ğ—¶ğ—ºğ—½ğ—¹ğ—²                   0      1                 0          0            0   \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»               0      1                 0          0            0   \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»ğ˜€              0      0                 0          0            0   \n",
      "\n",
      "             palm-2  claude-instant-v1  vicuna-7b  wizardlm-13b  \\\n",
      "00               87                 18         83             6   \n",
      "000             252                227         60            40   \n",
      "0000              1                  0          8             3   \n",
      "00000             0                  1          0             0   \n",
      "000000            2                  1          0             0   \n",
      "...             ...                ...        ...           ...   \n",
      "ï½”ï½                0                  0          0             0   \n",
      "ï½—ï½…ï½…ï½‹ï½“             0                  0          0             0   \n",
      "ğ˜€ğ—¶ğ—ºğ—½ğ—¹ğ—²            0                  0          0             0   \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»        0                  0          0             0   \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»ğ˜€       0                  0          0             0   \n",
      "\n",
      "             gpt4all-13b-snoozy  guanaco-33b  \n",
      "00                           28            3  \n",
      "000                          45           20  \n",
      "0000                         11            1  \n",
      "00000                         0            0  \n",
      "000000                        0            0  \n",
      "...                         ...          ...  \n",
      "ï½”ï½                            0            0  \n",
      "ï½—ï½…ï½…ï½‹ï½“                         0            0  \n",
      "ğ˜€ğ—¶ğ—ºğ—½ğ—¹ğ—²                        0            0  \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»                    0            0  \n",
      "ğ˜€ğ˜‚ğ—½ğ—²ğ—¿ğ—µğ˜‚ğ—ºğ—®ğ—»ğ˜€                   0            0  \n",
      "\n",
      "[195411 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group vectors by author and sum\n",
    "author_vectors = {}\n",
    "for i, author in enumerate(authors):\n",
    "    if author == 'human' :\n",
    "        continue\n",
    "    if author not in author_vectors:\n",
    "        author_vectors[author] = x_train[i].toarray()\n",
    "    else:\n",
    "        author_vectors[author] += x_train[i].toarray()\n",
    "\n",
    "# Convert to a more readable format (if needed)\n",
    "author_df = pd.DataFrame({author: vector.flatten() for author, vector in author_vectors.items()},\n",
    "                         index=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(author_df)  # Token counts for each author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "905cb5a4-0217-43e1-b377-a18c18b7074e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OpenCL and CUDA are two different programming ...</td>\n",
       "      <td>chatglm-6b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OpenCL and CUDA are both programming languages...</td>\n",
       "      <td>koala-13b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is possible that your parent did not invite...</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It is likely that they wanted to keep the gues...</td>\n",
       "      <td>alpaca-13b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Both Fuji and Nikon are popular camera brands ...</td>\n",
       "      <td>koala-13b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117940</th>\n",
       "      <td>1.\\t\"ì„¹ìŠ¤\"\\n2.\\t\"ì²´\"\\n3.\\t\"ìœ„\"\\n4.\\t\"ì\"\\n5.\\t\"ì„¸\"\\n...</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117942</th>\n",
       "      <td>Evaluating a language model output involves se...</td>\n",
       "      <td>guanaco-33b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117943</th>\n",
       "      <td>Evaluating the output of a language model invo...</td>\n",
       "      <td>koala-13b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117945</th>\n",
       "      <td>Power Automate is a powerful tool that allows ...</td>\n",
       "      <td>chatglm-6b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117946</th>\n",
       "      <td>Power Automate is a powerful tool that allows ...</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78632 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text            author\n",
       "0       OpenCL and CUDA are two different programming ...        chatglm-6b\n",
       "1       OpenCL and CUDA are both programming languages...         koala-13b\n",
       "3       It is possible that your parent did not invite...  oasst-pythia-12b\n",
       "4       It is likely that they wanted to keep the gues...        alpaca-13b\n",
       "6       Both Fuji and Nikon are popular camera brands ...         koala-13b\n",
       "...                                                   ...               ...\n",
       "117940  1.\\t\"ì„¹ìŠ¤\"\\n2.\\t\"ì²´\"\\n3.\\t\"ìœ„\"\\n4.\\t\"ì\"\\n5.\\t\"ì„¸\"\\n...  oasst-pythia-12b\n",
       "117942  Evaluating a language model output involves se...       guanaco-33b\n",
       "117943  Evaluating the output of a language model invo...         koala-13b\n",
       "117945  Power Automate is a powerful tool that allows ...        chatglm-6b\n",
       "117946  Power Automate is a powerful tool that allows ...      wizardlm-13b\n",
       "\n",
       "[78632 rows x 2 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_author_pairs_dataframe = pd.DataFrame(text_author_pairs)\n",
    "text_author_pairs_dataframe[text_author_pairs_dataframe['author'] != 'human']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7daf93ed-ec3e-4d34-8909-a108c694c3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [{'content': 'What is the difference between O...\n",
       "1    [{'content': 'Why did my parent not invite me ...\n",
       "2    [{'content': 'Fuji vs. Nikon, which is better?...\n",
       "3    [{'content': 'How to build an arena for chatbo...\n",
       "4    [{'content': 'When is it today?', 'role': 'use...\n",
       "Name: conversation_a, dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ready_for_conversion['conversation_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2d359f4a-e989-4fed-834c-ba93a63c1c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "wtf = pd.DataFrame({\n",
    "    \"conversation_a\": [\n",
    "        [\n",
    "            {\"content\": \"What is the difference between OpenCL and CUDA?\", \"role\": \"user\"},\n",
    "            {\"content\": \"OpenCL and CUDA are different programming models.\", \"role\": \"assistant\"}\n",
    "        ],\n",
    "        [\n",
    "            {\"content\": \"Why did my parent not invite me to the party?\", \"role\": \"user\"},\n",
    "            {\"content\": \"Perhaps they forgot, or you can ask them directly.\", \"role\": \"assistant\"}\n",
    "        ]\n",
    "    ],\n",
    "    \"conversation_b\": [\n",
    "        [\n",
    "            {\"content\": \"Could you explain artificial intelligence?\", \"role\": \"user\"},\n",
    "            {\"content\": \"Artificial intelligence is a fascinating field.\", \"role\": \"assistant\"}\n",
    "        ],\n",
    "        [\n",
    "            {\"content\": \"What is quantum computing?\", \"role\": \"user\"},\n",
    "            {\"content\": \"Quantum computing leverages quantum mechanics.\", \"role\": \"assistant\"}\n",
    "        ]\n",
    "    ],\n",
    "    \"model_a\": [\"chatglm-6b\", \"koala-13b\"],\n",
    "    \"model_b\": [\"oasst-pythia-12b\", \"vicuna-13b\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3f49d66b-0928-420e-bf99-0a1ea05b6a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_a</th>\n",
       "      <th>conversation_b</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'content': 'What is the difference between O...</td>\n",
       "      <td>[{'content': 'Could you explain artificial int...</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'content': 'Why did my parent not invite me ...</td>\n",
       "      <td>[{'content': 'What is quantum computing?', 'ro...</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>vicuna-13b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      conversation_a  \\\n",
       "0  [{'content': 'What is the difference between O...   \n",
       "1  [{'content': 'Why did my parent not invite me ...   \n",
       "\n",
       "                                      conversation_b     model_a  \\\n",
       "0  [{'content': 'Could you explain artificial int...  chatglm-6b   \n",
       "1  [{'content': 'What is quantum computing?', 'ro...   koala-13b   \n",
       "\n",
       "            model_b  \n",
       "0  oasst-pythia-12b  \n",
       "1        vicuna-13b  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5691cf28-c89d-4170-bf3a-5c07360d440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_df.to_csv('bruh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e582e8-af05-4aca-898f-eb441ba5814a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
